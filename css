import xlsxwriter
import glob
import selenium
import sys
sys.setrecursionlimit(100000)
from datetime import datetime
from time import gmtime, strftime, localtime
start_time = datetime.now()
from selenium import webdriver
from bs4 import BeautifulSoup as soup
import pandas as pd
import os
import time
import csv
import re
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.keys import Keys
import random
from selenium.webdriver.common.keys import Keys
import json
from urllib.parse import quote



def html_soup(browser):
    return soup(browser.page_source,"html.parser")

def zip_code_setter(browser, zip_code) :
    #run just once
    browser.get("https://www.amazon.com/")
    loaded = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.ID, "nav-global-location-popover-link")))
    button_clicker(browser, "nav-global-location-popover-link", "id",0,True)
    time.sleep(1)
    loaded = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.ID, "GLUXZipUpdateInput")))
    
    box = browser.find_element_by_id('GLUXZipUpdateInput')
    box.clear()
    
    box.send_keys(zip_code)
    box.send_keys(Keys.RETURN)
    
    loaded = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.ID, "GLUXConfirmClose")))
    button_clicker(browser, "GLUXConfirmClose", "id",0,True)
    
    return True

def delivery_time_getter(browser,link) :
    browser.get(link)
    page_soup = html_soup(browser)
    free_del = page_soup.findAll("div",{"id" : "deliveryBlockMessage"})[0].text.strip()
    return free_del
    



zip_code_setter(driver, "10128")


link= "https://www.amazon.com/Sonos-Move-Battery-powered-Bluetooth-built/dp/B07W95RBZM/"


delivery_time_getter(driver,link)
